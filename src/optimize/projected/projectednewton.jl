# Add a calculate_Œ≥ from Bertsekas.
# This is when an initial Œ± = 1 far oversteps the first point that hits a boundary
# on the piece-wise linear projected search path. This could be done always, never
# or if last search required a lot of line search reductions 

"""
# ActiveBox
## Constructor
```julia
    ActiveBox(; epsilon=1e-8)
```

`epsilon` determines the threshold for whether a bound is approximately active or not, see eqn. (32) in [1].

## Description
ActiveBox second order for bound constrained optimization. It's an active set and allows for rapid exploration of the constraint face. It employs a modified Armijo-line search that takes the active set into account. Details can be found in [1].

## References
[1] http://www.mit.edu/~dimitrib/ProjectedNewton.pdf
"""
struct ActiveBox{T}
    œµ::T
end
ActiveBox(; epsilon=1e-12) = ActiveBox(epsilon)
summary(::ActiveBox) = "ActiveBox"
modelscheme(::ActiveBox) = Newton()
"""
    diagrestrict(x, c, i)

Returns the correct element of the Hessian according to the active set and the diagonal matrix described in [1].

[1] http://www.mit.edu/~dimitrib/ProjectedNewton.pdf
"""
function diagrestrict(x::T, ci, cj, i) where T
    if !(ci | cj)
        # If not binding, then return the value
        return x
    else
        # If binding, then return 1 if the diagonal or 0 otherwise
        T(i)
    end
end

function is_œµ_active(x, lower, upper, ‚àáfx, œµ‚àáf=eltype(x)(0))
    # it is requied that œµ ‚©Ω min(U_i - L_i)/2 to uniquely choose
    # an underestimate of the inactive set or else there would be
    # two ways of defining ùìê^œµ.
    lowerbinding = x <= lower + œµ‚àáf
    upperbinding = x >= upper - œµ‚àáf

    pointing_down = ‚àáfx >= 0
    pointing_up   = ‚àáfx <= 0

    lower_active = lowerbinding && pointing_down
    upper_active = upperbinding && pointing_up

    lower_active || upper_active
end

isbinding(i, j) = i & j
function solve(prob::OptimizationProblem, x0, scheme::ActiveBox, options::OptimizationOptions)
    t0 = time()

    x0, B0 = x0, [1.0 0.0; 0.0 1.0]
    lower, upper = bounds(prob)
    œµbounds = mapreduce(b->(b[2] - b[1])/2, min, zip(lower, upper)) # [1, pp. 100: 5.41]

    !any(clamp.(x0, lower, upper) .!= x0) || error("Initial guess not in the feasible region")

    linesearch = ArmijoBertsekas()
    mstyle = OutOfPlace()

    objvars = prepare_variables(prob, scheme, x0, copy(x0), B0)
    f0, ‚àáf0 = objvars.fz, norm(objvars.‚àáfz, Inf) # use user norm
    fz, ‚àáfz = objvars.fz, objvars.‚àáfz # use user norm
    fx, ‚àáfx = fz, copy(‚àáfz)
    B = B0
    x, z = copy(x0), copy(x0)
    Tf = typeof(fz)
    is_first=false
    Ix = Diagonal(z.*0 .+ 1)
    for iter = 1:options.maxiter
        x = copy(z)
        fx = copy(fz)
        ‚àáfx = copy(‚àáfz)
 
        œµ = min(norm(clamp.(x.-‚àáfx, lower, upper).-x), œµbounds) # Kelley 5.41 and just after (83) in [1]
        activeset = is_œµ_active.(x, lower, upper, ‚àáfx, œµ)

        Hhat = diagrestrict.(B, activeset, activeset', Ix)
        # Update current gradient and calculate the search direction
        d = clamp.(x.-Hhat\‚àáfx, lower, upper).-x # solve Bd = -‚àáfx  #use find_direction here
        œÜ = _lineobjective(mstyle, prob, ‚àáfz, z, x, d, fz, dot(‚àáfz, d))

        # Perform line search along d
        # Also returns final step vector and update the state
        Œ±, f_Œ±, ls_success = find_steplength(mstyle, linesearch, œÜ, Tf(1), ‚àáfz, activeset, lower, upper, x, d, ‚àáfx, activeset)
        # # Calculate final step vector and update the state
        s = @. Œ± * d
        z = @. x + s
        s = clamp.(z, lower, upper) - x
        z = x + s
        
        # Update approximation
        fz, ‚àáfz, B, s, y = update_obj(prob.objective, s, ‚àáfx, z, ‚àáfz, B, Newton(), is_first)
        if norm(x.-clamp.(x.-‚àáfz, lower, upper), Inf) < options.g_abstol
            return ConvergenceInfo(scheme, (prob=prob, B=B, œÅs=norm(x.-z), œÅx=norm(x), minimizer=z, fx=fx, minimum=fz, ‚àáfz=‚àáfz, f0=f0, ‚àáf0=‚àáf0, iter=iter, time=time()-t0), options)
        end
    end
    @show z.-min.(upper, max.(z.-‚àáfz, lower))
  z, fz, options.maxiter
  return ConvergenceInfo(scheme, (prob=prob, B=B, œÅs=norm(x.-z), œÅx=norm(x), minimizer=z, fx=fx, minimum=fz, ‚àáfz=‚àáfz, f0=f0, ‚àáf0=‚àáf0, iter=iter, time=time()-t0), options)
end

"""
# ArmijoBertsekas
## Constructor
```julia
    ArmijoBertsekas()
```
## Description
ArmijoBertsekas is the modified Armijo backtracking line search described in [1]. It takes into account whether an element of the gradient is active or not.

## References
[1] http://www.mit.edu/~dimitrib/ActiveBox.pdf
"""
struct ArmijoBertsekas{T1, T2, T3, TR} <: LineSearcher
    ratio::T1
    decrease::T1
    maxiter::T2
    interp::T3
    steprange::TR
    verbose::Bool
end
ArmijoBertsekas(; ratio=0.5, decrease=1e-4, maxiter=50,
               steprange=(0.0, Inf), interp=FixedInterp(),
               verbose=false) =
 ArmijoBertsekas(ratio, decrease, maxiter, interp, steprange, verbose)

function find_steplength(mstyle, ls::ArmijoBertsekas, œÜ::T, Œª, ‚àáfx, Ibool, lower, upper, x, p, g, activeset) where T
    #== unpack ==#
    œÜ0, dœÜ0 = œÜ.œÜ0, œÜ.dœÜ0
    Tf = typeof(œÜ0)
    ratio, decrease, maxiter, verbose = Tf(ls.ratio), Tf(ls.decrease), ls.maxiter, ls.verbose

    #== factor in Armijo condition ==#
    t0 = decrease*dœÜ0 # dphi0 should take into account the active set
    iter, Œ±, Œ≤ = 0, Œª, Œª # iteration variables
    f_Œ± = œÜ(Œ±)   # initial function value
    x‚Å∫ = box_retract.(lower, upper, x, p, Œ±)

    if verbose
        println("Entering line search with step size: ", Œª)
        println("Initial value: ", œÜ0)
        println("Value at first step: ", f_Œ±)
    end
    is_solved = isfinite(f_Œ±.œï) && f_Œ±.œï <= œÜ0 - decrease*sum(bertsekas_R.(x, x‚Å∫, g, p, Œ±, activeset))
    while !is_solved && iter <= maxiter
        iter += 1
        Œ≤, Œ±, f_Œ± = interpolate(ls.interp, œÜ, œÜ0, dœÜ0, Œ±, f_Œ±.œï, ratio)
        x‚Å∫ = box_retract.(lower, upper, x, p, Œ±)
        is_solved = isfinite(f_Œ±.œï) && f_Œ±.œï <= œÜ0 - decrease*sum(bertsekas_R.(x, x‚Å∫, g, p, Œ±, activeset))
    end

    ls_success = iter >= maxiter ? false : true

    if verbose
        !ls_success && println("maxiter exceeded in backtracking")
        println("Exiting line search with step size: ", Œ±)
        println("Exiting line search with value: ", f_Œ±)
    end
    return Œ±, f_Œ±, ls_success
end

bertsekas_R(x, x‚Å∫, g, p, Œ±, i) = i ? g*(x-x‚Å∫) : Œ±*p*g
# defined univariately
# should be a "manifodl"
box_retract(lower, upper, x, p, Œ±) = min(upper, max(lower, x-Œ±*p))