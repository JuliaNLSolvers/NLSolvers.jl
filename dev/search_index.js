var documenterSearchIndex = {"docs":
[{"location":"nonlineareq/#Solving-non-linear-systems-of-equations","page":"Solving non-linear systems of equations","title":"Solving non-linear systems of equations","text":"","category":"section"},{"location":"leastsquares/#Non-linear-Least-Squares","page":"Non-linear Least Squares","title":"Non-linear Least Squares","text":"","category":"section"},{"location":"optimization/#Optimization","page":"Optimization","title":"Optimization","text":"","category":"section"},{"location":"optimization/#Univariate-optimization","page":"Optimization","title":"Univariate optimization","text":"","category":"section"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"Brent's method for minimizing a scalar objective is implemented as the BrentMin method. To solve it, you need to provide an objective and bounds.","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"brent_f(x) = sin(x)\nbrent_scalar = ScalarObjective(; f = brent_f)\nbrent_prob = OptimizationProblem(brent_scalar, (π/2, 2*π))\nsolve(brent_prob, BrentMin(), OptimizationOptions())","category":"page"},{"location":"optimization/#Multivariate-optimization","page":"Optimization","title":"Multivariate optimization","text":"","category":"section"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"Most applications of optimization software deals with multivariate optimization and there are many methods in the literature and in software that deals with these types of questions. Multivariate optimization can be unconstrained or constrained. We will show how to deal with these different cases below.","category":"page"},{"location":"optimization/#Unconstrained-optimization","page":"Optimization","title":"Unconstrained optimization","text":"","category":"section"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"If there are no constraints present, there are a lot of methods to choose from. They typically require an objective and an initial point. So-called gradient based methods, or first order methods, require gradients as well, and the second order methods require Hessian information as well. Some methods can even exploit Hessian-vector products.","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"To show how all the pieces fit together, we can try to find a local minimizer of the Himmelblau function.","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"function himmelblau!(x)\n    fx = (x[1]^2 + x[2] - 11)^2 + (x[1] + x[2]^2 - 7)^2\n    return fx\nend\nfunction himmelblau_g!(∇f, x)\n    ∇f[1] =\n        4.0 * x[1]^3 + 4.0 * x[1] * x[2] - 44.0 * x[1] + 2.0 * x[1] + 2.0 * x[2]^2 - 14.0\n    ∇f[2] =\n        2.0 * x[1]^2 + 2.0 * x[2] - 22.0 + 4.0 * x[1] * x[2] + 4.0 * x[2]^3 - 28.0 * x[2]\n    ∇f\nend\nfunction himmelblau_h!(∇²f, x)\n    ∇²f[1, 1] = 12.0 * x[1]^2 + 4.0 * x[2] - 44.0 + 2.0\n    ∇²f[1, 2] = 4.0 * x[1] + 4.0 * x[2]\n    ∇²f[2, 1] = ∇²f[1, 2]\n    ∇²f[2, 2] = 2.0 + 4.0 * x[1] + 12.0 * x[2]^2 - 28.0\n    return ∇²f\nend","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"The preceding functions define the objective, its gradient, and its Hessian. Notice, that the functions have to have the following input","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"objective functions require the current state x. It must return the objective value.\ngradient functions require the gradient container ∇f as the first argument and the state x as the second. It must return the gradient.\nHessian functions require the Hessian container ∇²f as the first argument and the state x as the second. It must return the Hessian.","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"Next, we wrap these up in the objective type","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"objective = ScalarObjective(\n    f=himmelblau!,\n    g=himmelblau_g!,\n\th=himmelblau_h!,\n    )","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"The ScalarObjective signifies that for any given input the objective returns a single number. This is contrary to non-linear systems of equations for example. We should also set an initial point to search from.","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"x0 = [3.0, 1.0]","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"Finally, we define the problem type.","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"prob = OptimizationProblem(objective)","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"Then, we solve it.","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"julia> results = solve(prob, x0, LineSearch(LBFGS()), OptimizationOptions())\nResults of minimization\n\n* Algorithm:\n  Inverse LBFGS with backtracking (no interp)\n\n* Candidate solution:\n  Final objective value:    2.53e-25\n  Final gradient norm:      3.87e-12\n\n  Initial objective value:  1.00e+01\n  Initial gradient norm:    1.80e+01\n\n* Stopping criteria\n  |x - x'|              = 1.94e-08 <= 0.00e+00 (false)\n  |x - x'|/|x|          = 5.37e-09 <= 0.00e+00 (false)\n  |f(x) - f(x')|        = 1.29e-14 <= 0.00e+00 (false)\n  |f(x) - f(x')|/|f(x)| = 1.00e+00 <= 0.00e+00 (false)\n  |g(x)|                = 3.87e-12 <= 1.00e-08 (true)\n  |g(x)|/|g(x₀)|        = 2.15e-13 <= 0.00e+00 (false)\n\n* Work counters\n  Seconds run:   1.79e-05\n  Iterations:    11","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"Since we have Hessian information available, we can also use variants of Newton's method.","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"results = solve(prob, x0, TrustRegion(Newton()), OptimizationOptions())\njulia> results = solve(prob, x0, TrustRegion(Newton()), OptimizationOptions())\nResults of minimization\n\n* Algorithm:\n  Newton's method with default linsolve with Trust Region (Newton, cholesky)\n\n* Candidate solution:\n  Final objective value:    7.10e-30\n  Final gradient norm:      2.84e-14\n\n  Initial objective value:  1.00e+01\n  Initial gradient norm:    1.80e+01\n\n* Stopping criteria\n  |x - x'|              = 2.73e-08 <= 0.00e+00 (false)\n  |x - x'|/|x|          = 6.50e-09 <= 0.00e+00 (false)\n  |f(x) - f(x')|        = 3.01e-14 <= 0.00e+00 (false)\n  |f(x) - f(x')|/|f(x)| = 1.00e+00 <= 0.00e+00 (false)\n  |g(x)|                = 2.84e-14 <= 1.00e-08 (true)\n  |g(x)|/|g(x₀)|        = 1.58e-15 <= 0.00e+00 (false)\n  Δ                     = 7.63e+04 <= 0.00e+00 (false)\n\n* Work counters\n  Seconds run:   6.39e-05\n  Iterations:    9","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"It is also possible to use methods that only use the objective to guide the search for an optimum. For example, it is possible to use the direct search method by Nelder and Mead.","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"julia> results = solve(prob, x0, NelderMead(), OptimizationOptions())\nResults of minimization\n\n* Algorithm:\n  Nelder-Mead\n\n* Candidate solution:\n  Final objective value:    0.00e+00\n\n  Initial objective value:  0.00e+00\n\n* Stopping criteria\n  √(Σ(yᵢ-ȳ)²)/n         = 9.58e-09 <= 1.00e-08 (true)\n\n* Work counters\n  Seconds run:   1.22e-02\n  Iterations:    32","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"We can also use a method based on sampling candidate solutions. Adaptive Particle Swarm is one such method. This method requires bounds on the state variable, so let us define a new optimization problem.","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"prob_bounds = OptimizationProblem(objective, ([0.0,0.0], [3.0,4.0]))","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"Then, we can solve the problem using ParticleSwarm. We set the maxiter option, because the method has no real termination criteria, but will keep iterating until maxiter has been reached.","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"julia> results = solve(prob_bounds, x0, ParticleSwarm(), OptimizationOptions(maxiter=38))\nResults of minimization\n\n* Algorithm:\n  Adaptive Particle Swarm\n\n* Candidate solution:\n  Final objective value:    8.46e-14\n\n  Initial objective value:  1.00e+01\n\n* Stopping criteria\n\n* Work counters\n  Seconds run:   2.49e-04\n  Iterations:    38","category":"page"},{"location":"optimization/#Box-constrained-problems","page":"Optimization","title":"Box constrained problems","text":"","category":"section"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"Box constraints, variable limits, and simple bounds are common names for variables where each individual parameter can have lower and upper bounds associated with them. We saw above how to enforce these bounds in the ParticleSwarm optimizer. There are other methods available. For example, ActiveBounds is a projected Newton's method. It was built for convex problem, so it can fail if the function is not locally convex","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"julia> solve(prob_bounds, [0.0, 1.8], ActiveBox(), OptimizationOptions())\nERROR: PosDefException: matrix is not positive definite; Cholesky factorization failed.\n...","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"However, it can often work well if you specify a factorization with modifications if negative eigenvalues are detected, such as the one in PositiveFactorizations.jl.","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"julia> solve(prob_bounds, [0.0, 1.8], ActiveBox(factorize=NLSolvers.positive_factorize), OptimizationOptions())\nResults of minimization\n\n* Algorithm:\n  ActiveBox\n\n* Candidate solution:\n  Final objective value:    3.16e-30\n  Final gradient norm:      2.84e-14\n  Final projected gradient norm:  7.11e-15\n\n  Initial objective value:  9.88e+01\n  Initial gradient norm:    4.55e+01\n\n* Stopping criteria\n  |x - x'|              = 1.02e-09 <= 0.00e+00 (false)\n  |x - x'|/|x|          = 2.82e-10 <= 0.00e+00 (false)\n  |f(x) - f(x')|        = 1.42e-17 <= 0.00e+00 (false)\n  |f(x) - f(x')|/|f(x)| = 1.00e+00 <= 0.00e+00 (false)\n  |x - P(x - g(x))|     = 7.11e-15 <= 1.00e-08 (true)\n  |g(x)|                = 2.84e-14 <= 1.00e-08 (true)\n  |g(x)|/|g(x₀)|        = 6.25e-16 <= 0.00e+00 (false)\n\n* Work counters\n  Seconds run:   1.26e-04\n  Iterations:    12\n","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"If the solution happens to end up at the boundary it will be printed as part of the show method for the results. The following example will lead to a solution at the boundary.","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"prob_bounds = OptimizationProblem(objective, ([0.0,0.0], [2.5,2.8]))","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"And has the following output.","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"julia> solve(prob_bounds, [0.0, 1.8], ActiveBox(factorize=NLSolvers.positive_factorize), OptimizationOptions())\nResults of minimization\n\n* Algorithm:\n  ActiveBox\n\n* Candidate solution:\n  Final objective value:    6.57e+00\n  Final gradient norm:      2.39e+01\n  Final projected gradient norm:  9.74e-11\n\n  Initial objective value:  9.88e+01\n  Initial gradient norm:    4.55e+01\n\n* Stopping criteria\n  |x - x'|              = 1.90e-06 <= 0.00e+00 (false)\n  |x - x'|/|x|          = 5.65e-07 <= 0.00e+00 (false)\n  |f(x) - f(x')|        = 8.07e-11 <= 0.00e+00 (false)\n  |f(x) - f(x')|/|f(x)| = 1.23e-11 <= 0.00e+00 (false)\n  |x - P(x - g(x))|     = 9.74e-11 <= 1.00e-08 (true)\n  |g(x)|                = 2.39e+01 <= 1.00e-08 (false)\n  |g(x)|/|g(x₀)|        = 5.26e-01 <= 0.00e+00 (false)\n\n  !!! Solution is at the boundary !!!\n\n* Work counters\n  Seconds run:   8.49e-05\n  Iterations:    9","category":"page"},{"location":"optimization/","page":"Optimization","title":"Optimization","text":"Notice, that the final gradient norm is way above the default threshold, but the norm of the projected gradient is indeed small. There is also a message that the solution is at the boundary.","category":"page"},{"location":"tutorials/precondition/#Preconditioners","page":"Preconditioners","title":"Preconditioners","text":"","category":"section"},{"location":"tutorials/precondition/","page":"Preconditioners","title":"Preconditioners","text":"It is possible to apply preconditioners to improve convergence on ill-conditioned problems. The interface across solvers is the same, but in different contexts, it means slightly different things.","category":"page"},{"location":"tutorials/precondition/","page":"Preconditioners","title":"Preconditioners","text":"As mentioned above, preconditioning is used to improve the conditioning of the problem at hand. A useful way to think about it is as a change of variables according to x = S*y, see [HZSurvey], where S is an invertible matrix. Writing the conjugate gradient descent, ConjugateGradient in this package, in the variable y, and changing it back to x, you obtain the equations","category":"page"},{"location":"tutorials/precondition/","page":"Preconditioners","title":"Preconditioners","text":"x' = x + α*d\nd' = P*g' + β*d","category":"page"},{"location":"tutorials/precondition/","page":"Preconditioners","title":"Preconditioners","text":"where P = S*S' is the preconditioner we will provide as the end-user, and g and d in the update formulae for β are replaced by S'g and inv(S)*d respectively. For this to be effective, P itself should represent the inverse of the actual Hessian of the objective function. ","category":"page"},{"location":"tutorials/precondition/","page":"Preconditioners","title":"Preconditioners","text":"The methods that accept preconditioners accept a P keyword in their constructors, for example","category":"page"},{"location":"tutorials/precondition/","page":"Preconditioners","title":"Preconditioners","text":"function precon(x, P=nothing)\n  if P isa Nothing\n    return InvDiagPrecon([1.0, 1.0, 1.0])\n  else\n    P.diag .= [1.0, 1.0, 1.0]\n    return P\n  end \nend\nBFGS(; P=precon)","category":"page"},{"location":"tutorials/precondition/","page":"Preconditioners","title":"Preconditioners","text":"Here, we're using the InvDiagPrecon preconditioner provided by this package. The preconditioner is applied using ldiv!(Pg, P, g) for in-place algorithms, and Pg = Pg\\g for out-of-oplace algorithms. Otherwise, unless a custom type is provided and methods are defined, it is applied using ldiv!(Pg, factorize(P), g) for in-place algorithms. Additionally, ConjugateGradient requires dot(x, P, y) to be defined for the preconditioner type as well. ","category":"page"},{"location":"#NLSolvers.jl","page":"NLSolvers.jl","title":"NLSolvers.jl","text":"","category":"section"},{"location":"","page":"NLSolvers.jl","title":"NLSolvers.jl","text":"Univariate and multivariate optimization and equation solving in Julia.","category":"page"},{"location":"","page":"NLSolvers.jl","title":"NLSolvers.jl","text":"NLSolvers.jl is the backend code for Optim.jl v2.0.0 and higher.","category":"page"},{"location":"#How","page":"NLSolvers.jl","title":"How","text":"","category":"section"},{"location":"","page":"NLSolvers.jl","title":"NLSolvers.jl","text":"The package is a registered package, and can be installed with Pkg.add.","category":"page"},{"location":"","page":"NLSolvers.jl","title":"NLSolvers.jl","text":"julia> using Pkg; Pkg.add(\"NLSolvers\")","category":"page"},{"location":"","page":"NLSolvers.jl","title":"NLSolvers.jl","text":"or through the pkg REPL mode by typing","category":"page"},{"location":"","page":"NLSolvers.jl","title":"NLSolvers.jl","text":"] add NLSolvers","category":"page"},{"location":"#What","page":"NLSolvers.jl","title":"What","text":"","category":"section"},{"location":"","page":"NLSolvers.jl","title":"NLSolvers.jl","text":"NLSolvers.jl is a Julia package for optimization, curve fitting and systems of nonlinear equations. The package requires full specification of the problem, so no smart constructors, automatic differentiation, or other user friendly features are present. If the focus is on ease of use, Optim.jl is the package to use.","category":"page"},{"location":"#Citing-the-package","page":"NLSolvers.jl","title":"Citing the package","text":"","category":"section"},{"location":"","page":"NLSolvers.jl","title":"NLSolvers.jl","text":"If you use NLSolvers.jl or Optim.jl in your work, please cite consider citing our paper in the Journal of Open Source Software. Citations give us the possibility to document the usage of the package, but it also gives us a way of following all the exciting ways in which NLSolvers.jl and Optim.jl are used in many fields fields including, but not limited to, optimization methods and software, economics, optics, physics, machine learning and more.","category":"page"},{"location":"","page":"NLSolvers.jl","title":"NLSolvers.jl","text":"(Image: JOSS) (Image: SCHOLAR)","category":"page"},{"location":"","page":"NLSolvers.jl","title":"NLSolvers.jl","text":"@article{mogensen2018optim,\n  title={Optim: A mathematical optimization package for Julia},\n  author={Mogensen, Patrick Kofod and Riseth, Asbj{\\o}rn Nilsen},\n  journal={Journal of Open Source Software},\n  volume={3},\n  number={24},\n  year={2018},\n  publisher={Open Journals}\n}","category":"page"}]
}
